# Terraform Infrastructure Deployment for ShopMefy
# This workflow creates complete AWS infrastructure for production environment
# 
# CONFIGURATION SUMMARY:
# - Cloud Provider: AWS
# - Environment: Development/Production
# - Database: RDS PostgreSQL managed with automatic backups
# - App Server: 1 EC2 t3.micro instance (scalable to t3.small)
# - Access: Public IP only (no custom domain)
# - Security: Basic Security Groups (SSH, HTTP, HTTPS, PostgreSQL)
# - Storage: S3 bucket for deployments + RDS backups (PRESERVED during destroy)
# - EC2 Setup: Pre-configured with Node.js, PM2, Nginx, user 'shopme'
# - Secrets: AWS Secrets Manager for database credentials + GitHub Secrets for API keys
# - API Keys: OpenRouter, HuggingFace, JWT Secret automatically configured
# - Environment: Complete .env file with all required variables
# - Monitoring: CloudWatch basic logging only
# - Deploy Flow: CI/CD ‚Üí S3 ‚Üí EC2 (compatible with existing deploy.yml)
# - Estimated Cost: ~$27-30/month
#
# REQUIRED GITHUB SECRETS:
# - AWS_ACCESS_KEY_ID: AWS access key for Terraform
# - AWS_SECRET_ACCESS_KEY: AWS secret key for Terraform  
# - OPENROUTER_API_KEY: API key for ChatGPT/Claude integration
# - HUGGINGFACE_API_KEY: API key for embeddings and document search
# - JWT_SECRET: Secret key for authentication tokens

name: üöÄ Deploy AWS Infrastructure with Terraform

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Terraform Action'
        required: true
        default: 'apply'
        type: choice
        options:
          - plan
          - apply
          - stop
          - cleanup-all
      instance_type:
        description: 'EC2 Instance Type'
        required: true
        default: 't3.micro'
        type: choice
        options:
          - t3.micro
          - t3.small
          - t3.medium

env:
  AWS_REGION: us-east-1
  TF_VERSION: 1.6.0

jobs:
  terraform:
    name: üèóÔ∏è Terraform Infrastructure
    runs-on: ubuntu-latest
    environment: dev
    
    steps:
      - name: üì• Checkout Repository
        uses: actions/checkout@v4

      - name: ‚öôÔ∏è Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: üîß Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: üìÅ Create Terraform Directory
        run: |
          mkdir -p ./terraform
          cd ./terraform

      - name: üßπ Cleanup All ShopMefy-Dev Resources
        if: github.event.inputs.action == 'cleanup-all'
        run: |
          echo "üßπ Starting COMPLETE cleanup of all shopmefy-dev* resources..."
          echo "‚ö†Ô∏è  WARNING: This will remove EVERYTHING including S3 buckets and all data!"
          
          # Install AWS CLI if not available
          if ! command -v aws &> /dev/null; then
            echo "Installing AWS CLI..."
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install
          fi
          
          # Set AWS region
          export AWS_DEFAULT_REGION=${{ env.AWS_REGION }}
          
          echo "üîç Finding and deleting ALL shopmefy-dev* resources..."
          
          # Delete EC2 instances
          echo "üñ•Ô∏è Deleting EC2 instances..."
          INSTANCES=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=shopmefy-dev*" --query "Reservations[].Instances[?State.Name!='terminated'].InstanceId" --output text)
          if [ ! -z "$INSTANCES" ]; then
            echo "Terminating instances: $INSTANCES"
            aws ec2 terminate-instances --instance-ids $INSTANCES
            aws ec2 wait instance-terminated --instance-ids $INSTANCES
          fi
          
          # Release Elastic IPs
          echo "üåê Releasing Elastic IPs..."
          EIPS=$(aws ec2 describe-addresses --filters "Name=tag:Name,Values=shopmefy-dev*" --query "Addresses[].AllocationId" --output text)
          for eip in $EIPS; do
            if [ ! -z "$eip" ]; then
              echo "Releasing EIP: $eip"
              aws ec2 release-address --allocation-id $eip
            fi
          done
          
          # Delete RDS instances
          echo "üóÑÔ∏è Deleting RDS instances..."
          RDS_INSTANCES=$(aws rds describe-db-instances --query "DBInstances[?starts_with(DBInstanceIdentifier, 'shopmefy-dev')].DBInstanceIdentifier" --output text)
          for db in $RDS_INSTANCES; do
            if [ ! -z "$db" ]; then
              echo "Deleting RDS instance: $db"
              aws rds delete-db-instance --db-instance-identifier $db --skip-final-snapshot --delete-automated-backups
            fi
          done
          
          # Delete DB Subnet Groups
          echo "üîó Deleting DB Subnet Groups..."
          DB_SUBNET_GROUPS=$(aws rds describe-db-subnet-groups --query "DBSubnetGroups[?starts_with(DBSubnetGroupName, 'shopmefy-dev')].DBSubnetGroupName" --output text)
          for sg in $DB_SUBNET_GROUPS; do
            if [ ! -z "$sg" ]; then
              echo "Deleting DB Subnet Group: $sg"
              aws rds delete-db-subnet-group --db-subnet-group-name $sg
            fi
          done
          
          # Delete S3 buckets and ALL content
          echo "üóëÔ∏è Deleting S3 buckets and ALL content..."
          S3_BUCKETS=$(aws s3api list-buckets --query "Buckets[?starts_with(Name, 'shopmefy-dev')].Name" --output text)
          for bucket in $S3_BUCKETS; do
            if [ ! -z "$bucket" ]; then
              echo "Emptying and deleting S3 bucket: $bucket"
              aws s3 rm s3://$bucket --recursive
              aws s3api delete-bucket --bucket $bucket
            fi
          done
          
          # Delete Secrets Manager secrets
          echo "üîê Deleting Secrets Manager secrets..."
          SECRETS=$(aws secretsmanager list-secrets --query "SecretList[?starts_with(Name, 'shopmefy-dev')].Name" --output text)
          for secret in $SECRETS; do
            if [ ! -z "$secret" ]; then
              echo "Deleting secret: $secret"
              aws secretsmanager delete-secret --secret-id $secret --force-delete-without-recovery
            fi
          done
          
          # Delete Key Pairs
          echo "üîë Deleting Key Pairs..."
          KEY_PAIRS=$(aws ec2 describe-key-pairs --query "KeyPairs[?starts_with(KeyName, 'shopmefy-dev')].KeyName" --output text)
          for key in $KEY_PAIRS; do
            if [ ! -z "$key" ]; then
              echo "Deleting key pair: $key"
              aws ec2 delete-key-pair --key-name $key
            fi
          done
          
          # Delete Security Groups (after instances are terminated)
          echo "üõ°Ô∏è Deleting Security Groups..."
          sleep 30  # Wait for instances to be fully terminated
          SECURITY_GROUPS=$(aws ec2 describe-security-groups --filters "Name=tag:Name,Values=shopmefy-dev*" --query "SecurityGroups[?GroupName!='default'].GroupId" --output text)
          for sg in $SECURITY_GROUPS; do
            if [ ! -z "$sg" ]; then
              echo "Deleting security group: $sg"
              aws ec2 delete-security-group --group-id $sg || echo "Failed to delete $sg (may have dependencies)"
            fi
          done
          
          # Delete VPC and related resources
          echo "üåê Deleting VPC resources..."
          VPCS=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=shopmefy-dev*" --query "Vpcs[].VpcId" --output text)
          for vpc in $VPCS; do
            if [ ! -z "$vpc" ]; then
              echo "Deleting VPC: $vpc"
              
              # Delete route table associations and route tables
              ROUTE_TABLES=$(aws ec2 describe-route-tables --filters "Name=vpc-id,Values=$vpc" --query "RouteTables[?Associations[0].Main!=\`true\`].RouteTableId" --output text)
              for rt in $ROUTE_TABLES; do
                if [ ! -z "$rt" ]; then
                  # Disassociate route tables
                  ASSOCIATIONS=$(aws ec2 describe-route-tables --route-table-ids $rt --query "RouteTables[].Associations[?Main!=\`true\`].RouteTableAssociationId" --output text)
                  for assoc in $ASSOCIATIONS; do
                    if [ ! -z "$assoc" ]; then
                      aws ec2 disassociate-route-table --association-id $assoc
                    fi
                  done
                  aws ec2 delete-route-table --route-table-id $rt
                fi
              done
              
              # Delete subnets
              SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$vpc" --query "Subnets[].SubnetId" --output text)
              for subnet in $SUBNETS; do
                if [ ! -z "$subnet" ]; then
                  aws ec2 delete-subnet --subnet-id $subnet
                fi
              done
              
              # Delete internet gateway
              IGWS=$(aws ec2 describe-internet-gateways --filters "Name=attachment.vpc-id,Values=$vpc" --query "InternetGateways[].InternetGatewayId" --output text)
              for igw in $IGWS; do
                if [ ! -z "$igw" ]; then
                  aws ec2 detach-internet-gateway --internet-gateway-id $igw --vpc-id $vpc
                  aws ec2 delete-internet-gateway --internet-gateway-id $igw
                fi
              done
              
              # Finally delete VPC
              aws ec2 delete-vpc --vpc-id $vpc
            fi
          done
          
          # Delete CloudWatch Log Groups
          echo "üìä Deleting CloudWatch Log Groups..."
          LOG_GROUPS=$(aws logs describe-log-groups --log-group-name-prefix "/aws/ec2/shopmefy-dev" --query "logGroups[].logGroupName" --output text)
          for lg in $LOG_GROUPS; do
            if [ ! -z "$lg" ]; then
              echo "Deleting log group: $lg"
              aws logs delete-log-group --log-group-name $lg
            fi
          done
          
          echo ""
          echo "üéâ COMPLETE CLEANUP FINISHED!"
          echo "üóëÔ∏è ALL shopmefy-dev* resources have been permanently removed"
          echo "üí∞ No more AWS charges for this infrastructure"
          echo "üîÑ You can create fresh infrastructure anytime with 'apply'"
          echo ""
          echo "## üßπ Complete Infrastructure Cleanup Successful!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ‚úÖ Everything Removed:" >> $GITHUB_STEP_SUMMARY
          echo "- üñ•Ô∏è **EC2 instances** - Terminated and removed" >> $GITHUB_STEP_SUMMARY
          echo "- üóÑÔ∏è **RDS databases** - Deleted with all data" >> $GITHUB_STEP_SUMMARY
          echo "- üóëÔ∏è **S3 buckets** - Emptied and deleted completely" >> $GITHUB_STEP_SUMMARY
          echo "- üîê **Secrets Manager** - All secrets removed" >> $GITHUB_STEP_SUMMARY
          echo "- üîë **SSH Key Pairs** - Deleted" >> $GITHUB_STEP_SUMMARY
          echo "- üõ°Ô∏è **Security Groups** - Removed" >> $GITHUB_STEP_SUMMARY
          echo "- üåê **VPC & Networking** - Complete network cleanup" >> $GITHUB_STEP_SUMMARY
          echo "- üìä **CloudWatch Logs** - Log groups deleted" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üí∞ Result:" >> $GITHUB_STEP_SUMMARY
          echo "- **Zero AWS costs** - No resources left running" >> $GITHUB_STEP_SUMMARY
          echo "- **Clean slate** - Ready for fresh deployment anytime" >> $GITHUB_STEP_SUMMARY
          echo "- **No traces** - All shopmefy-dev infrastructure completely removed" >> $GITHUB_STEP_SUMMARY

      - name: üìù Generate Terraform Configuration
        if: github.event.inputs.action != 'cleanup-all'
        working-directory: ./terraform
        run: |
          cat > main.tf << 'EOF'
          # ===================================
          # SHOPMEFY AWS INFRASTRUCTURE - DEV VERSION
          # ===================================
          
          terraform {
            required_version = ">= 1.0"
            required_providers {
              aws = {
                source  = "hashicorp/aws"
                version = "~> 5.0"
              }
              random = {
                source  = "hashicorp/random"
                version = "~> 3.1"
              }
              tls = {
                source  = "hashicorp/tls"
                version = "~> 4.0"
              }
            }
          }
          
          provider "aws" {
            region = var.aws_region
            
            default_tags {
              tags = {
                Project     = "ShopMefy"
                Environment = "development"
                ManagedBy   = "Terraform"
                Owner       = "Andrea"
              }
            }
          }
          
          # ===================================
          # VARIABLES
          # ===================================
          
          variable "aws_region" {
            description = "AWS region"
            type        = string
            default     = "us-east-1"
          }
          
          variable "instance_type" {
            description = "EC2 instance type"
            type        = string
            default     = "t3.micro"
          }
          
          variable "project_name" {
            description = "Project name"
            type        = string
            default     = "shopmefy-dev"
          }
          
          # ===================================
          # DATA SOURCES
          # ===================================
          
          data "aws_availability_zones" "available" {
            state = "available"
          }
          
          data "aws_ami" "ubuntu" {
            most_recent = true
            owners      = ["099720109477"] # Canonical
            
            filter {
              name   = "name"
              values = ["ubuntu/images/hvm-ssd/ubuntu-*-amd64-server-*"]
            }
            
            filter {
              name   = "virtualization-type"
              values = ["hvm"]
            }
          }
          
          # ===================================
          # RANDOM RESOURCES
          # ===================================
          
          resource "random_password" "db_password" {
            length  = 16
            special = true
          }
          
          resource "random_id" "bucket_suffix" {
            byte_length = 4
          }
          
          # ===================================
          # VPC AND NETWORKING
          # ===================================
          
          resource "aws_vpc" "main" {
            cidr_block           = "10.0.0.0/16"
            enable_dns_hostnames = true
            enable_dns_support   = true
            
            tags = {
              Name = "${var.project_name}-vpc"
            }
          }
          
          resource "aws_internet_gateway" "main" {
            vpc_id = aws_vpc.main.id
            
            tags = {
              Name = "${var.project_name}-igw"
            }
          }
          
          resource "aws_subnet" "public" {
            count = 2
            
            vpc_id                  = aws_vpc.main.id
            cidr_block              = "10.0.${count.index + 1}.0/24"
            availability_zone       = data.aws_availability_zones.available.names[count.index]
            map_public_ip_on_launch = true
            
            tags = {
              Name = "${var.project_name}-public-subnet-${count.index + 1}"
            }
          }
          
          resource "aws_subnet" "private" {
            count = 2
            
            vpc_id            = aws_vpc.main.id
            cidr_block        = "10.0.${count.index + 10}.0/24"
            availability_zone = data.aws_availability_zones.available.names[count.index]
            
            tags = {
              Name = "${var.project_name}-private-subnet-${count.index + 1}"
            }
          }
          
          resource "aws_route_table" "public" {
            vpc_id = aws_vpc.main.id
            
            route {
              cidr_block = "0.0.0.0/0"
              gateway_id = aws_internet_gateway.main.id
            }
            
            tags = {
              Name = "${var.project_name}-public-rt"
            }
          }
          
          resource "aws_route_table_association" "public" {
            count = length(aws_subnet.public)
            
            subnet_id      = aws_subnet.public[count.index].id
            route_table_id = aws_route_table.public.id
          }
          
          # ===================================
          # SECURITY GROUPS
          # ===================================
          
          resource "aws_security_group" "web" {
            name_prefix = "${var.project_name}-web-"
            vpc_id      = aws_vpc.main.id
            description = "Security group for web server"
            
            # SSH
            ingress {
              from_port   = 22
              to_port     = 22
              protocol    = "tcp"
              cidr_blocks = ["0.0.0.0/0"]
              description = "SSH"
            }
            
            # HTTP
            ingress {
              from_port   = 80
              to_port     = 80
              protocol    = "tcp"
              cidr_blocks = ["0.0.0.0/0"]
              description = "HTTP"
            }
            
            # HTTPS
            ingress {
              from_port   = 443
              to_port     = 443
              protocol    = "tcp"
              cidr_blocks = ["0.0.0.0/0"]
              description = "HTTPS"
            }
            
            # Node.js App Port
            ingress {
              from_port   = 8080
              to_port     = 8080
              protocol    = "tcp"
              cidr_blocks = ["0.0.0.0/0"]
              description = "Node.js Application"
            }
            
            egress {
              from_port   = 0
              to_port     = 0
              protocol    = "-1"
              cidr_blocks = ["0.0.0.0/0"]
              description = "All outbound traffic"
            }
            
            tags = {
              Name = "${var.project_name}-web-sg"
            }
          }
          
          resource "aws_security_group" "database" {
            name_prefix = "${var.project_name}-db-"
            vpc_id      = aws_vpc.main.id
            description = "Security group for RDS database"
            
            ingress {
              from_port       = 5432
              to_port         = 5432
              protocol        = "tcp"
              security_groups = [aws_security_group.web.id]
              description     = "PostgreSQL from web servers"
            }
            
            tags = {
              Name = "${var.project_name}-db-sg"
            }
          }
          
          # ===================================
          # SSH KEY PAIR
          # ===================================
          
          resource "tls_private_key" "main" {
            algorithm = "RSA"
            rsa_bits  = 4096
          }
          
          resource "aws_key_pair" "main" {
            key_name   = "${var.project_name}-key"
            public_key = tls_private_key.main.public_key_openssh
            
            tags = {
              Name = "${var.project_name}-keypair"
            }
          }
          
          # ===================================
          # S3 BUCKET FOR DEPLOYMENTS (PRESERVED)
          # ===================================
          
          resource "aws_s3_bucket" "deployments" {
            bucket = "${var.project_name}-deployments-${random_id.bucket_suffix.hex}"
            
            tags = {
              Name = "${var.project_name}-deployments"
              Preserve = "true"
            }
            
            lifecycle {
              prevent_destroy = true
            }
          }
          
          resource "aws_s3_bucket_versioning" "deployments" {
            bucket = aws_s3_bucket.deployments.id
            versioning_configuration {
              status = "Enabled"
            }
          }
          
          resource "aws_s3_bucket_server_side_encryption_configuration" "deployments" {
            bucket = aws_s3_bucket.deployments.id
            
            rule {
              apply_server_side_encryption_by_default {
                sse_algorithm = "AES256"
              }
            }
          }
          
          resource "aws_s3_bucket_public_access_block" "deployments" {
            bucket = aws_s3_bucket.deployments.id
            
            block_public_acls       = true
            block_public_policy     = true
            ignore_public_acls      = true
            restrict_public_buckets = true
          }
          
          # ===================================
          # AWS SECRETS MANAGER FOR DATABASE
          # ===================================
          
          resource "aws_secretsmanager_secret" "db_credentials" {
            name                    = "${var.project_name}-db-credentials"
            description             = "Database credentials for ShopMefy"
            recovery_window_in_days = 7
          }
          
          # ===================================
          # RDS SUBNET GROUP
          # ===================================
          
          resource "aws_db_subnet_group" "main" {
            name       = "${var.project_name}-db-subnet-group"
            subnet_ids = aws_subnet.private[*].id
            
            tags = {
              Name = "${var.project_name}-db-subnet-group"
            }
          }
          
          # ===================================
          # RDS POSTGRESQL DATABASE
          # ===================================
          
          resource "aws_db_instance" "postgres" {
            identifier = "${var.project_name}-db"
            
            # Engine
            engine         = "postgres"
            engine_version = "15.10"
            instance_class = "db.t3.micro"
            
            # Storage
            allocated_storage     = 20
            max_allocated_storage = 100
            storage_type          = "gp2"
            storage_encrypted     = true
            
            # Database
            db_name  = "shopmefy"
            username = "shopmefy"
            password = random_password.db_password.result
            
            # Network
            db_subnet_group_name   = aws_db_subnet_group.main.name
            vpc_security_group_ids = [aws_security_group.database.id]
            publicly_accessible    = false
            
            # Backup
            backup_retention_period = 7
            backup_window          = "03:00-04:00"
            maintenance_window     = "sun:04:00-sun:05:00"
            
            # Other
            skip_final_snapshot = true
            deletion_protection = false
            
            tags = {
              Name = "${var.project_name}-database"
            }
          }
          
          # ===================================
          # SECRETS MANAGER VERSION (AFTER RDS)
          # ===================================
          
          resource "aws_secretsmanager_secret_version" "db_credentials" {
            secret_id = aws_secretsmanager_secret.db_credentials.id
            secret_string = jsonencode({
              username = "shopmefy"
              password = random_password.db_password.result
              engine   = "postgres"
              host     = aws_db_instance.postgres.endpoint
              port     = 5432
              dbname   = "shopmefy"
            })
            
            depends_on = [aws_db_instance.postgres]
          }
          
          # ===================================
          # EC2 INSTANCE
          # ===================================
          
          resource "aws_instance" "web" {
            ami                    = data.aws_ami.ubuntu.id
            instance_type          = var.instance_type
            key_name               = aws_key_pair.main.key_name
            vpc_security_group_ids = [aws_security_group.web.id]
            subnet_id              = aws_subnet.public[0].id
            
            # Simple user data - basic setup only
            user_data = base64encode(<<-EOF
              #!/bin/bash
              apt-get update
              apt-get install -y nginx
              systemctl start nginx
              systemctl enable nginx
              echo "<h1>ShopMefy Server Ready</h1>" > /var/www/html/index.html
            EOF
            )
            
            root_block_device {
              volume_type = "gp3"
              volume_size = 20
              encrypted   = true
            }
            
            tags = {
              Name = "${var.project_name}-web-server"
            }
            
            depends_on = [
              aws_vpc.main,
              aws_subnet.public,
              aws_security_group.web,
              aws_key_pair.main
            ]
          }
          
          # ===================================
          # ELASTIC IP
          # ===================================
          
          resource "aws_eip" "web" {
            instance = aws_instance.web.id
            domain   = "vpc"
            
            tags = {
              Name = "${var.project_name}-eip"
            }
            
            depends_on = [aws_instance.web]
          }
          
          # ===================================
          # OUTPUTS
          # ===================================
          
          output "web_public_ip" {
            description = "Public IP address of the web server"
            value       = aws_eip.web.public_ip
          }
          
          output "web_public_dns" {
            description = "Public DNS name of the web server"
            value       = aws_eip.web.public_dns
          }
          
          output "database_endpoint" {
            description = "RDS instance endpoint"
            value       = aws_db_instance.postgres.endpoint
            sensitive   = true
          }
          
          output "database_host" {
            description = "RDS instance host (without port)"
            value       = split(":", aws_db_instance.postgres.endpoint)[0]
            sensitive   = true
          }
          
          output "s3_bucket_name" {
            description = "S3 bucket name for deployments"
            value       = aws_s3_bucket.deployments.bucket
          }
          
          output "secret_manager_arn" {
            description = "AWS Secrets Manager ARN for database credentials"
            value       = aws_secretsmanager_secret.db_credentials.arn
          }
          
          output "ssh_private_key" {
            description = "SSH private key for connecting to the server"
            value       = tls_private_key.main.private_key_pem
            sensitive   = true
          }
          
          output "ssh_command" {
            description = "SSH command to connect to the server"
            value       = "ssh -i shopmefy_key.pem ubuntu@${aws_eip.web.public_ip}"
          }
          
          output "database_password" {
            description = "Database password"
            value       = random_password.db_password.result
            sensitive   = true
          }
          
          output "database_url" {
            description = "Complete database URL"
            value       = "postgresql://shopmefy:${random_password.db_password.result}@${split(":", aws_db_instance.postgres.endpoint)[0]}:5432/shopmefy"
            sensitive   = true
          }
          EOF

      - name: üîß Terraform Init
        working-directory: ./terraform
        if: github.event.inputs.action != 'cleanup-all'
        run: terraform init

      - name: ‚úÖ Terraform Validate
        working-directory: ./terraform
        if: github.event.inputs.action != 'cleanup-all'
        run: terraform validate

      - name: üìã Terraform Plan
        working-directory: ./terraform
        if: github.event.inputs.action == 'plan'
        run: |
          terraform plan \
            -var="instance_type=${{ github.event.inputs.instance_type }}" \
            -out=tfplan

      - name: üöÄ Terraform Apply
        working-directory: ./terraform
        if: github.event.inputs.action == 'apply'
        run: |
          terraform apply \
            -var="instance_type=${{ github.event.inputs.instance_type }}" \
            -auto-approve

      - name: üìä Show Outputs
        working-directory: ./terraform
        if: github.event.inputs.action == 'apply'
        run: |
          echo "## üéâ Infrastructure Deployed Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìã Connection Details:" >> $GITHUB_STEP_SUMMARY
          echo "- **Public IP**: $(terraform output -raw web_public_ip)" >> $GITHUB_STEP_SUMMARY
          echo "- **Public DNS**: $(terraform output -raw web_public_dns)" >> $GITHUB_STEP_SUMMARY
          echo "- **SSH Command**: \`$(terraform output -raw ssh_command)\`" >> $GITHUB_STEP_SUMMARY
          echo "- **S3 Bucket**: $(terraform output -raw s3_bucket_name)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üîß Next Steps:" >> $GITHUB_STEP_SUMMARY
          echo "1. Update your \`deploy.yml\` with the new S3 bucket name" >> $GITHUB_STEP_SUMMARY
          echo "2. Update your \`deploy.yml\` with the new EC2 IP address" >> $GITHUB_STEP_SUMMARY
          echo "3. Run your existing CI/CD pipeline to deploy the application" >> $GITHUB_STEP_SUMMARY

      - name: ü§ñ Auto-Update GitHub Secrets
        working-directory: ./terraform
        if: github.event.inputs.action == 'apply'
        continue-on-error: true
        run: |
          # Get all outputs
          S3_BUCKET=$(terraform output -raw s3_bucket_name)
          EC2_HOST=$(terraform output -raw web_public_ip)
          SSH_PRIVATE_KEY=$(terraform output -raw ssh_private_key)
          DB_HOST=$(terraform output -raw database_host)
          DB_PASSWORD=$(terraform output -raw database_password)
          DATABASE_URL=$(terraform output -raw database_url)
          
          echo "üîÑ Attempting automatic secret update with GitHub CLI for DEV environment..."
          
          # Install GitHub CLI if not available
          if ! command -v gh &> /dev/null; then
            echo "Installing GitHub CLI..."
            curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
            sudo apt update
            sudo apt install gh -y
          fi
          
          # Authenticate with GitHub token
          echo "${{ secrets.GITHUB_TOKEN }}" | gh auth login --with-token
          
          # Update infrastructure secrets in DEV environment
          echo "$S3_BUCKET" | gh secret set S3_BUCKET_NAME --repo ${{ github.repository }} --env dev
          echo "$EC2_HOST" | gh secret set EC2_HOST --repo ${{ github.repository }} --env dev
          echo "ubuntu" | gh secret set EC2_USER --repo ${{ github.repository }} --env dev
          echo "us-east-1" | gh secret set AWS_REGION --repo ${{ github.repository }} --env dev
          echo "$SSH_PRIVATE_KEY" | gh secret set EC2_SSH_KEY --repo ${{ github.repository }} --env dev
          
          # Add database secrets
          echo "$DATABASE_URL" | gh secret set DATABASE_URL --repo ${{ github.repository }} --env dev
          echo "shopmefy" | gh secret set DB_NAME --repo ${{ github.repository }} --env dev
          echo "shopmefy" | gh secret set DB_USER --repo ${{ github.repository }} --env dev
          echo "$DB_PASSWORD" | gh secret set DB_PASSWORD --repo ${{ github.repository }} --env dev
          echo "$DB_HOST" | gh secret set DB_HOST --repo ${{ github.repository }} --env dev
          
          echo "‚úÖ All secrets updated automatically via GitHub CLI in DEV environment!"
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üéâ Complete Infrastructure Secrets Auto-Updated in DEV Environment:" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ S3_BUCKET_NAME" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ EC2_HOST" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ EC2_USER" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ AWS_REGION" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ EC2_SSH_KEY (Generated automatically)" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ DATABASE_URL" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ DB_NAME" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ DB_USER" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ DB_PASSWORD" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ DB_HOST" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üéØ Ready for Production!" >> $GITHUB_STEP_SUMMARY
          echo "1. **Complete infrastructure** - EC2 + RDS + S3 + SSH access" >> $GITHUB_STEP_SUMMARY
          echo "2. **All secrets configured** - Database and deployment secrets ready" >> $GITHUB_STEP_SUMMARY
          echo "3. **Deploy your application** - Use the deploy.yml workflow" >> $GITHUB_STEP_SUMMARY

      - name: ‚èπÔ∏è Stop Infrastructure (Cost Saving)
        if: github.event.inputs.action == 'stop'
        run: |
          echo "‚èπÔ∏è Stopping ShopMefy-Dev infrastructure to save costs..."
          
          # Install AWS CLI if not available
          if ! command -v aws &> /dev/null; then
            echo "Installing AWS CLI..."
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install
          fi
          
          # Set AWS region
          export AWS_DEFAULT_REGION=${{ env.AWS_REGION }}
          
          echo "üîç Finding shopmefy-dev* resources to stop..."
          
          # Stop EC2 instances
          echo "üñ•Ô∏è Stopping EC2 instances..."
          INSTANCES=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=shopmefy-dev*" "Name=instance-state-name,Values=running" --query "Reservations[].Instances[].InstanceId" --output text)
          if [ ! -z "$INSTANCES" ]; then
            echo "Stopping instances: $INSTANCES"
            aws ec2 stop-instances --instance-ids $INSTANCES
            echo "‚úÖ EC2 instances stopped successfully"
          else
            echo "‚ÑπÔ∏è No running EC2 instances found"
          fi
          
          # Stop RDS instances
          echo "üóÑÔ∏è Stopping RDS instances..."
          RDS_INSTANCES=$(aws rds describe-db-instances --query "DBInstances[?starts_with(DBInstanceIdentifier, 'shopmefy-dev') && DBInstanceStatus=='available'].DBInstanceIdentifier" --output text)
          for db in $RDS_INSTANCES; do
            if [ ! -z "$db" ]; then
              echo "Stopping RDS instance: $db"
              aws rds stop-db-instance --db-instance-identifier $db
              echo "‚úÖ RDS instance $db stopped successfully"
            fi
          done
          
          if [ -z "$RDS_INSTANCES" ]; then
            echo "‚ÑπÔ∏è No available RDS instances found to stop"
          fi
          
          echo ""
          echo "üéâ Infrastructure stopped successfully!"
          echo "üí∞ Cost savings: EC2 and RDS instances are now stopped"
          echo "üìã Infrastructure preserved: All configurations, data, and S3 buckets remain intact"
          echo "üöÄ To restart: Run this workflow with 'apply' action"
          echo ""
          echo "## ‚èπÔ∏è Infrastructure Stopped Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üí∞ Cost Savings Activated:" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **EC2 instances stopped** - No compute charges" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **RDS instances stopped** - No database charges" >> $GITHUB_STEP_SUMMARY
          echo "- üõ°Ô∏è **All data preserved** - Configurations and data intact" >> $GITHUB_STEP_SUMMARY
          echo "- üì¶ **S3 buckets active** - Minimal storage costs only" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üöÄ To Restart Infrastructure:" >> $GITHUB_STEP_SUMMARY
          echo "1. Run this workflow again with **'apply'** action" >> $GITHUB_STEP_SUMMARY
          echo "2. All services will restart with existing configurations" >> $GITHUB_STEP_SUMMARY
          echo "3. No data loss - everything will be exactly as before" >> $GITHUB_STEP_SUMMARY 